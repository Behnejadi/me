{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simplenet_mnist_(2) (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK0RSG6Hx6kD"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten ,Dropout\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l2\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.initializers import glorot_normal, RandomNormal, Zeros\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc ,accuracy_score,precision_score,recall_score,f1_score,accuracy_score\n",
        "from keras.models import Model, model_from_json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UrozZw5zmiN"
      },
      "source": [
        "image_size = 28\n",
        "num_channels = 1\n",
        "num_features = image_size * image_size * num_channels\n",
        "num_classes = 10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEIXKvqH82Ut",
        "outputId": "3ac335cb-7e9b-4be0-ac5b-5392f987c2c0"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('Train data shape: {}'.format(x_train.shape))\n",
        "print('Test  data shape: {}'.format(x_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train data shape: (60000, 28, 28)\n",
            "Test  data shape: (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz4tAISq7Stx",
        "outputId": "fe78cc5d-478b-4a0a-dd51-477caf96a9fa"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test  = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnZDthVcSH5m",
        "outputId": "50754e3b-3cdf-423e-f8a7-97835181ff97"
      },
      "source": [
        "npad = ((0,0), (2,2), (2,2), (0,0))\n",
        "x_train = np.pad(x_train, pad_width=npad, mode='constant', constant_values=0)\n",
        "x_test = np.pad(x_test, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 32, 32, 1)\n",
            "(10000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXi459NY88eb",
        "outputId": "271cfa21-498b-446c-cdcb-d84806e5751a"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh-YSPIrHrQf"
      },
      "source": [
        "# plotting helper function\n",
        "def plothist(hist):\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(hist.history['accuracy'])\n",
        "    plt.plot(hist.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2V2aJZ2zmSH"
      },
      "source": [
        "def create_cnn():\n",
        "    model = Sequential()\n",
        "    # Conv Block 1\n",
        "    model.add(Conv2D(64, (3, 3), padding='same' , strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal() ,\n",
        "                     input_shape=x_train.shape[1:]))\n",
        "    model.add(BatchNormalization(momentum=0.05,trainable=True, epsilon=1e-05))# affine=True, track_running_stats=True\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=RandomNormal(stddev=0.01)))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "     \n",
        "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=RandomNormal(stddev=0.01)))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "     \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
        "    model.add(Dropout(0.1))          \n",
        "\n",
        "\n",
        "    # Conv Block 2\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=RandomNormal(stddev=0.01)))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "     \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "    # Conv Block 3\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "     \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    # Conv Block 4\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "     \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    # Conv Block 5\n",
        "    model.add(Conv2D(2048, (1, 1), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "    model.add(Conv2D(256, (1, 1), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "     \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "    # Conv Block 6\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
        "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
        "    model.add(Activation(activation='relu'))#(inplace)\n",
        "\n",
        "\n",
        "    # Classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "#model = create_cnn()\n",
        "#model.summary()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAmYHu678di"
      },
      "source": [
        "BATCH_SIZE =100\n",
        "STEPS_PER_EPOCH =len(x_train)//BATCH_SIZE \n",
        "\n",
        "step = tf.Variable(0, trainable=False)\n",
        "boundaries = [25*STEPS_PER_EPOCH,50*STEPS_PER_EPOCH,\n",
        "              75*STEPS_PER_EPOCH]\n",
        "values = [0.1, 0.01 , 0.001, 0.0001]\n",
        "learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries, values)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV5InGkZg9Q0"
      },
      "source": [
        "def create_model():\n",
        "    model = create_cnn()\n",
        "    #model.save_weights(\"tmp.h5\")\n",
        "\n",
        "    # optionally do some other modifications (freezing layers, adding convolutions etc.)\n",
        "    \n",
        "    WEIGHT_DECAY=0.002\n",
        "\n",
        "    regularizer = l2(WEIGHT_DECAY / 2)\n",
        "    for layer in model.layers:\n",
        "        for attr in ['kernel_regularizer', 'bias_regularizer']:\n",
        "            if hasattr(layer, attr) and layer.trainable:\n",
        "                setattr(layer, attr, regularizer)\n",
        "\n",
        "    out = model_from_json(model.to_json())\n",
        "    #out.load_weights(\"tmp.h5\", by_name=True)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEkUCuZShOGb"
      },
      "source": [
        "model=create_model()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIUYtaAI8ENq"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_fn)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14GLLTvuC3Y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0827375-8d7b-4a34-a681-94d341baf73b"
      },
      "source": [
        "history =model.fit(x_train, y_train, batch_size=100,\n",
        "                   steps_per_epoch=len(x_train) //100,epochs=100,\n",
        "                   validation_data=(x_test,y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.7976 - accuracy: 0.9459WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_test_batch_end` time: 0.0117s). Check your callbacks.\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 2.7970 - accuracy: 0.9460 - val_loss: 2.3708 - val_accuracy: 0.9886\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 2.1293 - accuracy: 0.9856 - val_loss: 1.8746 - val_accuracy: 0.9915\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 1.6846 - accuracy: 0.9896 - val_loss: 1.4891 - val_accuracy: 0.9918\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 1.3360 - accuracy: 0.9915 - val_loss: 1.1829 - val_accuracy: 0.9928\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 1.0627 - accuracy: 0.9923 - val_loss: 0.9428 - val_accuracy: 0.9941\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.8486 - accuracy: 0.9929 - val_loss: 0.7621 - val_accuracy: 0.9904\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.6768 - accuracy: 0.9943 - val_loss: 0.6041 - val_accuracy: 0.9941\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.5490 - accuracy: 0.9931 - val_loss: 0.4899 - val_accuracy: 0.9936\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.4441 - accuracy: 0.9938 - val_loss: 0.3994 - val_accuracy: 0.9932\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.3620 - accuracy: 0.9939 - val_loss: 0.3370 - val_accuracy: 0.9917\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.2980 - accuracy: 0.9939 - val_loss: 0.2772 - val_accuracy: 0.9927\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.2490 - accuracy: 0.9938 - val_loss: 0.2278 - val_accuracy: 0.9941\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.2108 - accuracy: 0.9936 - val_loss: 0.1911 - val_accuracy: 0.9944\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.1774 - accuracy: 0.9946 - val_loss: 0.1670 - val_accuracy: 0.9937\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.1519 - accuracy: 0.9944 - val_loss: 0.1666 - val_accuracy: 0.9847\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.1339 - accuracy: 0.9941 - val_loss: 0.1249 - val_accuracy: 0.9943\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.1183 - accuracy: 0.9944 - val_loss: 0.1117 - val_accuracy: 0.9944\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.1041 - accuracy: 0.9949 - val_loss: 0.1090 - val_accuracy: 0.9934\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0955 - accuracy: 0.9948 - val_loss: 0.1023 - val_accuracy: 0.9913\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0886 - accuracy: 0.9947 - val_loss: 0.0810 - val_accuracy: 0.9953\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0813 - accuracy: 0.9951 - val_loss: 0.0771 - val_accuracy: 0.9950\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0758 - accuracy: 0.9951 - val_loss: 0.0831 - val_accuracy: 0.9923\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0734 - accuracy: 0.9950 - val_loss: 0.0778 - val_accuracy: 0.9933\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0720 - accuracy: 0.9947 - val_loss: 0.0767 - val_accuracy: 0.9923\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0672 - accuracy: 0.9953 - val_loss: 0.0732 - val_accuracy: 0.9927\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0559 - accuracy: 0.9982 - val_loss: 0.0629 - val_accuracy: 0.9949\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0520 - accuracy: 0.9993 - val_loss: 0.0602 - val_accuracy: 0.9961\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0505 - accuracy: 0.9993 - val_loss: 0.0594 - val_accuracy: 0.9954\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0488 - accuracy: 0.9996 - val_loss: 0.0584 - val_accuracy: 0.9957\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0475 - accuracy: 0.9996 - val_loss: 0.0578 - val_accuracy: 0.9957\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0465 - accuracy: 0.9996 - val_loss: 0.0586 - val_accuracy: 0.9951\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0454 - accuracy: 0.9997 - val_loss: 0.0560 - val_accuracy: 0.9960\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0442 - accuracy: 0.9997 - val_loss: 0.0548 - val_accuracy: 0.9961\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0432 - accuracy: 0.9998 - val_loss: 0.0541 - val_accuracy: 0.9963\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0422 - accuracy: 0.9998 - val_loss: 0.0539 - val_accuracy: 0.9960\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0414 - accuracy: 0.9998 - val_loss: 0.0548 - val_accuracy: 0.9959\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0404 - accuracy: 0.9998 - val_loss: 0.0534 - val_accuracy: 0.9956\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0395 - accuracy: 0.9998 - val_loss: 0.0514 - val_accuracy: 0.9960\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0386 - accuracy: 0.9998 - val_loss: 0.0510 - val_accuracy: 0.9961\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0379 - accuracy: 0.9999 - val_loss: 0.0507 - val_accuracy: 0.9963\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0370 - accuracy: 0.9998 - val_loss: 0.0514 - val_accuracy: 0.9957\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0361 - accuracy: 0.9999 - val_loss: 0.0484 - val_accuracy: 0.9960\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0354 - accuracy: 0.9999 - val_loss: 0.0482 - val_accuracy: 0.9960\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0347 - accuracy: 0.9999 - val_loss: 0.0504 - val_accuracy: 0.9954\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0339 - accuracy: 0.9999 - val_loss: 0.0486 - val_accuracy: 0.9960\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0332 - accuracy: 0.9999 - val_loss: 0.0461 - val_accuracy: 0.9966\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0325 - accuracy: 0.9999 - val_loss: 0.0462 - val_accuracy: 0.9964\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0319 - accuracy: 0.9999 - val_loss: 0.0445 - val_accuracy: 0.9960\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0312 - accuracy: 0.9999 - val_loss: 0.0437 - val_accuracy: 0.9962\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0304 - accuracy: 0.9999 - val_loss: 0.0434 - val_accuracy: 0.9958\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0301 - accuracy: 0.9999 - val_loss: 0.0448 - val_accuracy: 0.9958\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9950\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9958\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9959\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9959\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9964\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0297 - accuracy: 0.9999 - val_loss: 0.0428 - val_accuracy: 0.9963\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9961\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9961\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9955\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0295 - accuracy: 0.9999 - val_loss: 0.0444 - val_accuracy: 0.9959\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9964\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 28s 47ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9966\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9959\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9962\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9963\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0292 - accuracy: 0.9999 - val_loss: 0.0439 - val_accuracy: 0.9960\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9964\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9964\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9962\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9956\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9960\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9964\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9951\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9967\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 0.9999 - val_loss: 0.0441 - val_accuracy: 0.9951\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9962\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9963\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9963\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 0.9999 - val_loss: 0.0424 - val_accuracy: 0.9962\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9964\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9961\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 0.9999 - val_loss: 0.0418 - val_accuracy: 0.9959\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9963\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9966\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9961\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9958\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9967\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9955\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9962\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9964\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9964\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9959\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9960\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9958\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9961\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 0.9999 - val_loss: 0.0418 - val_accuracy: 0.9964\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9964\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9958\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 29s 48ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJHddu4V8r_g"
      },
      "source": [
        "#model.save('mnist.simplenet.99.52.h5')\n",
        "                 \n",
        "#model=load_model('mnist.simplenet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHfzaHUx8wXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32391448-acd9-451c-ff65-e9f64947df35"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "labels1 = np.arange(num_classes)\n",
        "print('Auc = %f' %  (roc_auc_score(y_test,  y_pred.round(),average='macro',multi_class='ovo',labels=labels1)))\n",
        "print('f1_score = %f' % (f1_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('precision = %f' % (precision_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('recall  = %f' % (recall_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('accuracy  = %f' % (accuracy_score(y_test, y_pred.round())))  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc = 0.998105\n",
            "f1_score = 0.996679\n",
            "precision = 0.996795\n",
            "recall  = 0.996565\n",
            "accuracy  = 0.996600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zbiSEgJhPFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f252df89-16b5-4e94-bd14-54098ffb5a65"
      },
      "source": [
        "plothist(history)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}