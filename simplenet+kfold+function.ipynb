{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "F8ESUWX_ZNqD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten ,Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import regularizers, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.initializers import glorot_normal, RandomNormal, Zeros\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc ,accuracy_score,precision_score,recall_score,f1_score,accuracy_score\n",
    "import datetime, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uUUokvA_uPRY"
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    dataset = np.load('data.row.battah/ASD_process.npz') #Dataset ready in numpy array (removing background, resizing, and transforming into grayscale)\n",
    "    X = dataset['X']\n",
    "    y = dataset['y']\n",
    "\n",
    "    mean = np.mean(X, axis=(0, 1, 2,3))\n",
    "    std = np.std(X, axis=(0, 1, 2,3))\n",
    "    X = (X - mean) / (std+1e-7)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DFfNdiAC4ZCK"
   },
   "outputs": [],
   "source": [
    "def GetModel():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Conv Block 1\n",
    "    model.add(Conv2D(64, (3, 3), padding='same' , strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal(),\n",
    "                     input_shape=X[train].shape[1:]))\n",
    "    model.add(BatchNormalization(momentum=0.05,trainable=True, epsilon=1e-05))# affine=True, track_running_stats=True\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "     \n",
    "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "     \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
    "    model.add(Dropout(0.1))          \n",
    "\n",
    "\n",
    "    # Conv Block 2\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "     \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    # Conv Block 3\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "     \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Conv Block 4\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "     \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Conv Block 5\n",
    "    model.add(Conv2D(2048, (1, 1), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "    model.add(Conv2D(256, (1, 1), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "     \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))# padding=0, dilation=(1, 1), ceil_mode=False)\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    # Conv Block 6\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization(momentum=0.05, epsilon=1e-05))\n",
    "    model.add(Activation(activation='relu'))#(inplace)\n",
    "\n",
    "\n",
    "    # Classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    BATCH_SIZE =64\n",
    "    STEPS_PER_EPOCH =len(X[train])//BATCH_SIZE \n",
    "    step = tf.Variable(0, trainable=False)\n",
    "    boundaries = [15*STEPS_PER_EPOCH,30*STEPS_PER_EPOCH,\n",
    "              40*STEPS_PER_EPOCH]\n",
    "    values = [0.1, 0.01 , 0.001, 0.0001]\n",
    "    learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries, values)\n",
    "\n",
    "\n",
    "    opt = SGD(learning_rate=learning_rate_fn(step))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MhumcaHKUg9F"
   },
   "outputs": [],
   "source": [
    "def train_cross_validate(folds = 3):\n",
    "    histories = []\n",
    "    models = []\n",
    "\n",
    "    X, y = get_dataset()\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "    kfold = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=1).split(X, y) \n",
    "    \n",
    "\n",
    "\n",
    "    for train, test in kfold:\n",
    "        model = GetModel()\n",
    "        history = model.fit(X[train], y[train], validation_split=0.3,batch_size=64,\n",
    "                  epochs=50,steps_per_epoch = len(X[train])//64,validation_steps = len([test])//64,\n",
    "                   validation_data=(X[test], y[test]),shuffle=True)\n",
    "       \n",
    "        models.append(model)\n",
    "        histories.append(history)\n",
    "        \n",
    "    return histories, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "er0obYxjSaAS"
   },
   "outputs": [],
   "source": [
    "def predict(folds = 3):\n",
    "   X, y = get_dataset()\n",
    "   histories, models = train_cross_validate(folds = folds)\n",
    "   \n",
    "\n",
    "   scores=[]\n",
    "   auc =[]\n",
    "   tprs = []\n",
    "   aucs = []\n",
    "   accuracy =[]\n",
    "   recall =[]\n",
    "   precision = []\n",
    "   mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    \n",
    "\n",
    "   for i in range(nfolds):\n",
    "     result = models[i].evaluate(X[test], y[test], verbose=0)\n",
    "     scores.append(result)\n",
    "     pred = models[i].predict(X[test])\n",
    "     AUC = roc_auc_score(y[test], pred.round())\n",
    "     auc.append(AUC)\n",
    "     recall.append( recall_score(y[test], pred.round()) )\n",
    "     precision.append( precision_score(y[test], pred.round()) )\n",
    "     accuracy.append(accuracy_score(y[test], pred.round()))\n",
    "   return precision, auc ,accuracy,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "Ebyg9uoHmhDt",
    "outputId": "f4031bac-6f33-44d5-c945-d875da9998fd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7a46e03e7cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-594cbbb9532a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(folds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m    \u001b[0mhistories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a80187ae00f9>\u001b[0m in \u001b[0;36mtrain_cross_validate\u001b[0;34m(folds)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         history = model.fit(X[train], y[train], validation_split=0.3,batch_size=64,\n\u001b[1;32m     15\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4e73a9694337>\u001b[0m in \u001b[0;36mGetModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Conv Block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model.add(Conv2D(64, (3, 3), padding='same' , strides=(1, 1),kernel_regularizer=regularizers.l2(0.005), kernel_initializer=glorot_normal(),\n\u001b[0;32m----> 6\u001b[0;31m                      input_shape=X[train].shape[1:]))\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# affine=True, track_running_stats=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(inplace)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "precision, auc ,accuracy,recall= predict(folds = 3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simplenet+kfold+function (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
