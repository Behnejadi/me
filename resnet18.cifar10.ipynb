{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18+cifar10_(6) (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ESUWX_ZNqD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense, Activation ,AveragePooling2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc,precision_score, recall_score,f1_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy import interp\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "import scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Lambda, Input\n",
        "from keras.models import Model, Sequential\n",
        "import tensorflow as ktf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYG194TF_w9d",
        "outputId": "849065ee-cd20-44c3-b587-dd545683bc2b"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('Train data shape: {}'.format(X_train.shape))\n",
        "print('Test  data shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape: (50000, 32, 32, 3)\n",
            "Test  data shape: (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y68QeKy_EIn5"
      },
      "source": [
        "image_size = 32\n",
        "num_channels = 3\n",
        "num_features = image_size * image_size * num_channels\n",
        "num_classes = 10"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grGv0zltDvh5",
        "outputId": "81194f88-084c-42cc-c125-cc451230e42f"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "x_test  = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255.0\n",
        "mean = np.mean(X_train, axis=(0, 1, 2,3))\n",
        "std = np.std(X_train, axis=(0, 1, 2,3))\n",
        "X_train = (X_train - mean)/ (std+1e-7)\n",
        "\n",
        "x_test /= 255.0\n",
        "\n",
        "x_test =(x_test-mean) / (std+1e-7)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(x_test.shape)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGctKnwPDvXT",
        "outputId": "0cf23d1c-f790-4488-ddfd-5e0b53882f14"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwZZdax7GjhE"
      },
      "source": [
        "# plotting helper function\n",
        "def plothist(hist):\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(hist.history['accuracy'])\n",
        "    plt.plot(hist.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUs8Of18sIiP",
        "outputId": "84b78bcb-fe9d-492b-dd60-16a9d601e31c"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-_cyl97ki\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-_cyl97ki\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied (use --upgrade to upgrade): image-classifiers==1.0.0 from git+https://github.com/qubvel/classification_models.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from image-classifiers==1.0.0) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.15.0)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-cp36-none-any.whl size=20031 sha256=9eb68f7741f8fc5d0fef73ffec3cbe11346880e76a8e33672f0740deef41e987\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c4cf67nk/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
            "Successfully built image-classifiers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhgtSsJFsif"
      },
      "source": [
        "from classification_models.tfkeras import Classifiers"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo_Uj8cjZNTE",
        "outputId": "9c0282c0-dd01-4afb-e0e1-9d65114f65b8"
      },
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "resnet18 = ResNet18((224, 224, 3), weights='imagenet')\n",
        "resnet18.summary() "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 224, 224, 3)  9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_36 (ZeroPadding2 (None, 230, 230, 3)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 112, 112, 64) 9408        zero_padding2d_36[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 112, 112, 64) 256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 112, 112, 64) 0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_37 (ZeroPadding2 (None, 114, 114, 64) 0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 56, 56, 64)   0           zero_padding2d_37[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 56, 56, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 56, 56, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_38 (ZeroPadding2 (None, 58, 58, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_38[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 56, 56, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 56, 56, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_39 (ZeroPadding2 (None, 58, 58, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_39[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 56, 56, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 56, 56, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 56, 56, 64)   256         add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 56, 56, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_40 (ZeroPadding2 (None, 58, 58, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_40[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 56, 56, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 56, 56, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_41 (ZeroPadding2 (None, 58, 58, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_41[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 56, 56, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 56, 56, 64)   256         add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 56, 56, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_42 (ZeroPadding2 (None, 58, 58, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 28, 28, 128)  73728       zero_padding2d_42[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 28, 28, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 28, 28, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_43 (ZeroPadding2 (None, 30, 30, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 28, 28, 128)  147456      zero_padding2d_43[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 28, 28, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 28, 28, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 28, 28, 128)  512         add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 28, 28, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_44 (ZeroPadding2 (None, 30, 30, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 28, 28, 128)  147456      zero_padding2d_44[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 28, 28, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 28, 28, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_45 (ZeroPadding2 (None, 30, 30, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 28, 28, 128)  147456      zero_padding2d_45[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 28, 28, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 28, 28, 128)  512         add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 28, 28, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_46 (ZeroPadding2 (None, 30, 30, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 14, 14, 256)  294912      zero_padding2d_46[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 14, 14, 256)  1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 14, 14, 256)  0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_47 (ZeroPadding2 (None, 16, 16, 256)  0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 14, 14, 256)  589824      zero_padding2d_47[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 14, 14, 256)  32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 14, 14, 256)  0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 14, 14, 256)  1024        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, 14, 14, 256)  0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_48 (ZeroPadding2 (None, 16, 16, 256)  0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, 14, 14, 256)  589824      zero_padding2d_48[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, 14, 14, 256)  1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, 14, 14, 256)  0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_49 (ZeroPadding2 (None, 16, 16, 256)  0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, 14, 14, 256)  589824      zero_padding2d_49[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 14, 14, 256)  0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, 14, 14, 256)  1024        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, 14, 14, 256)  0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_50 (ZeroPadding2 (None, 16, 16, 256)  0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, 7, 7, 512)    1179648     zero_padding2d_50[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, 7, 7, 512)    2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, 7, 7, 512)    0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_51 (ZeroPadding2 (None, 9, 9, 512)    0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, 7, 7, 512)    2359296     zero_padding2d_51[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, 7, 7, 512)    131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 7, 7, 512)    0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, 7, 7, 512)    2048        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, 7, 7, 512)    0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_52 (ZeroPadding2 (None, 9, 9, 512)    0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, 7, 7, 512)    2359296     zero_padding2d_52[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, 7, 7, 512)    2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, 7, 7, 512)    0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_53 (ZeroPadding2 (None, 9, 9, 512)    0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, 7, 7, 512)    2359296     zero_padding2d_53[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 7, 7, 512)    0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 7, 7, 512)    2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 7, 7, 512)    0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (GlobalAveragePooling2D)  (None, 512)          0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 1000)         513000      pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 1000)         0           fc1[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 11,699,889\n",
            "Trainable params: 11,691,947\n",
            "Non-trainable params: 7,942\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tebKLPNJmVD"
      },
      "source": [
        "alpha = 0.003  # weight decay coefficient\n",
        "\n",
        "for layer in resnet18.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "        layer.add_loss(lambda: keras.regularizers.l2(alpha)(layer.kernel))\n",
        "    if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "        layer.add_loss(lambda: keras.regularizers.l2(alpha)(layer.bias))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qy5h2dZNNz"
      },
      "source": [
        "x = resnet18.layers[-2].output\r\n",
        "output = Dense(units=10,activation='softmax')(x)\r\n",
        "model = Model(inputs=[resnet18.input], outputs=[output])\r\n",
        "#model.summary()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFARn69XZNGR",
        "outputId": "157c8911-f037-48fa-843b-9cafe64d4bbb"
      },
      "source": [
        "for layer in model.layers[35:]:\n",
        "    layer.trainable = True\n",
        "for layer in model.layers[:35]:\n",
        "    layer.trainable = False\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 data False\n",
            "1 bn_data False\n",
            "2 zero_padding2d_36 False\n",
            "3 conv0 False\n",
            "4 bn0 False\n",
            "5 relu0 False\n",
            "6 zero_padding2d_37 False\n",
            "7 pooling0 False\n",
            "8 stage1_unit1_bn1 False\n",
            "9 stage1_unit1_relu1 False\n",
            "10 zero_padding2d_38 False\n",
            "11 stage1_unit1_conv1 False\n",
            "12 stage1_unit1_bn2 False\n",
            "13 stage1_unit1_relu2 False\n",
            "14 zero_padding2d_39 False\n",
            "15 stage1_unit1_conv2 False\n",
            "16 stage1_unit1_sc False\n",
            "17 add_16 False\n",
            "18 stage1_unit2_bn1 False\n",
            "19 stage1_unit2_relu1 False\n",
            "20 zero_padding2d_40 False\n",
            "21 stage1_unit2_conv1 False\n",
            "22 stage1_unit2_bn2 False\n",
            "23 stage1_unit2_relu2 False\n",
            "24 zero_padding2d_41 False\n",
            "25 stage1_unit2_conv2 False\n",
            "26 add_17 False\n",
            "27 stage2_unit1_bn1 False\n",
            "28 stage2_unit1_relu1 False\n",
            "29 zero_padding2d_42 False\n",
            "30 stage2_unit1_conv1 False\n",
            "31 stage2_unit1_bn2 False\n",
            "32 stage2_unit1_relu2 False\n",
            "33 zero_padding2d_43 False\n",
            "34 stage2_unit1_conv2 False\n",
            "35 stage2_unit1_sc True\n",
            "36 add_18 True\n",
            "37 stage2_unit2_bn1 True\n",
            "38 stage2_unit2_relu1 True\n",
            "39 zero_padding2d_44 True\n",
            "40 stage2_unit2_conv1 True\n",
            "41 stage2_unit2_bn2 True\n",
            "42 stage2_unit2_relu2 True\n",
            "43 zero_padding2d_45 True\n",
            "44 stage2_unit2_conv2 True\n",
            "45 add_19 True\n",
            "46 stage3_unit1_bn1 True\n",
            "47 stage3_unit1_relu1 True\n",
            "48 zero_padding2d_46 True\n",
            "49 stage3_unit1_conv1 True\n",
            "50 stage3_unit1_bn2 True\n",
            "51 stage3_unit1_relu2 True\n",
            "52 zero_padding2d_47 True\n",
            "53 stage3_unit1_conv2 True\n",
            "54 stage3_unit1_sc True\n",
            "55 add_20 True\n",
            "56 stage3_unit2_bn1 True\n",
            "57 stage3_unit2_relu1 True\n",
            "58 zero_padding2d_48 True\n",
            "59 stage3_unit2_conv1 True\n",
            "60 stage3_unit2_bn2 True\n",
            "61 stage3_unit2_relu2 True\n",
            "62 zero_padding2d_49 True\n",
            "63 stage3_unit2_conv2 True\n",
            "64 add_21 True\n",
            "65 stage4_unit1_bn1 True\n",
            "66 stage4_unit1_relu1 True\n",
            "67 zero_padding2d_50 True\n",
            "68 stage4_unit1_conv1 True\n",
            "69 stage4_unit1_bn2 True\n",
            "70 stage4_unit1_relu2 True\n",
            "71 zero_padding2d_51 True\n",
            "72 stage4_unit1_conv2 True\n",
            "73 stage4_unit1_sc True\n",
            "74 add_22 True\n",
            "75 stage4_unit2_bn1 True\n",
            "76 stage4_unit2_relu1 True\n",
            "77 zero_padding2d_52 True\n",
            "78 stage4_unit2_conv1 True\n",
            "79 stage4_unit2_bn2 True\n",
            "80 stage4_unit2_relu2 True\n",
            "81 zero_padding2d_53 True\n",
            "82 stage4_unit2_conv2 True\n",
            "83 add_23 True\n",
            "84 bn1 True\n",
            "85 relu1 True\n",
            "86 pool1 True\n",
            "87 fc1 True\n",
            "88 dense_2 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2eux2vSQ4d-"
      },
      "source": [
        "newInput = Input(batch_shape=(None, 32, 32, 3))\r\n",
        "resizedImg = Lambda(lambda image: ktf.image.resize(image, (224, 224)))(newInput)\r\n",
        "newOutputs = model(resizedImg)\r\n",
        "model = Model(newInput, newOutputs)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhYMg5wDGLls"
      },
      "source": [
        "BATCH_SIZE =100\n",
        "STEPS_PER_EPOCH =len(X_train)//BATCH_SIZE \n",
        "\n",
        "step = tf.Variable(0, trainable=False)\n",
        "boundaries = [30*STEPS_PER_EPOCH,50*STEPS_PER_EPOCH,80*STEPS_PER_EPOCH]\n",
        "values = [ 0.1, 0.01,0.001,0.0001]\n",
        "learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries, values)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtTrzDGTZNDX"
      },
      "source": [
        "opt = SGD(learning_rate=learning_rate_fn)#,momentum=0.9,decay=0.01,nesterov=False\n",
        "#opt = Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.99,epsilon=0.1,amsgrad=False,name=\"Adam\",)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBYnLBGlFN2o"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foLD5c3UHD2X",
        "outputId": "2d6dc395-1cd0-4d51-bce5-1b8a1c25ca79"
      },
      "source": [
        "history =model.fit(X_train, y_train, batch_size=100,\n",
        "                   steps_per_epoch=len(X_train) // 100,epochs=100,\n",
        "                   validation_data=(x_test,y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 4.1593 - accuracy: 0.1506 - val_loss: 6.1092 - val_accuracy: 0.0958\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.7771 - accuracy: 0.1995 - val_loss: 3.7073 - val_accuracy: 0.2122\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.5883 - accuracy: 0.2327 - val_loss: 3.5569 - val_accuracy: 0.2413\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.4682 - accuracy: 0.2575 - val_loss: 3.4493 - val_accuracy: 0.2651\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.3816 - accuracy: 0.2781 - val_loss: 3.3712 - val_accuracy: 0.2832\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.3147 - accuracy: 0.2963 - val_loss: 3.3099 - val_accuracy: 0.2988\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.2610 - accuracy: 0.3090 - val_loss: 3.2583 - val_accuracy: 0.3078\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.2152 - accuracy: 0.3246 - val_loss: 3.2160 - val_accuracy: 0.3186\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.1763 - accuracy: 0.3352 - val_loss: 3.1784 - val_accuracy: 0.3299\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.1421 - accuracy: 0.3451 - val_loss: 3.1468 - val_accuracy: 0.3393\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.1137 - accuracy: 0.3530 - val_loss: 3.1178 - val_accuracy: 0.3469\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.0848 - accuracy: 0.3617 - val_loss: 3.0920 - val_accuracy: 0.3547\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.0621 - accuracy: 0.3694 - val_loss: 3.0694 - val_accuracy: 0.3614\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.0413 - accuracy: 0.3751 - val_loss: 3.0479 - val_accuracy: 0.3662\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.0190 - accuracy: 0.3797 - val_loss: 3.0281 - val_accuracy: 0.3737\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 3.0010 - accuracy: 0.3877 - val_loss: 3.0101 - val_accuracy: 0.3806\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.9833 - accuracy: 0.3920 - val_loss: 2.9929 - val_accuracy: 0.3889\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.9659 - accuracy: 0.3963 - val_loss: 2.9759 - val_accuracy: 0.3914\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.9501 - accuracy: 0.4021 - val_loss: 2.9609 - val_accuracy: 0.3986\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.9351 - accuracy: 0.4066 - val_loss: 2.9455 - val_accuracy: 0.4039\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.9201 - accuracy: 0.4102 - val_loss: 2.9313 - val_accuracy: 0.4066\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.9064 - accuracy: 0.4145 - val_loss: 2.9180 - val_accuracy: 0.4105\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8935 - accuracy: 0.4184 - val_loss: 2.9054 - val_accuracy: 0.4131\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8816 - accuracy: 0.4219 - val_loss: 2.8933 - val_accuracy: 0.4174\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8691 - accuracy: 0.4250 - val_loss: 2.8815 - val_accuracy: 0.4198\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8577 - accuracy: 0.4287 - val_loss: 2.8703 - val_accuracy: 0.4227\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8444 - accuracy: 0.4342 - val_loss: 2.8591 - val_accuracy: 0.4257\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8331 - accuracy: 0.4374 - val_loss: 2.8482 - val_accuracy: 0.4286\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8239 - accuracy: 0.4388 - val_loss: 2.8379 - val_accuracy: 0.4309\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8132 - accuracy: 0.4416 - val_loss: 2.8276 - val_accuracy: 0.4344\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8060 - accuracy: 0.4443 - val_loss: 2.8266 - val_accuracy: 0.4360\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8052 - accuracy: 0.4445 - val_loss: 2.8257 - val_accuracy: 0.4371\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8049 - accuracy: 0.4454 - val_loss: 2.8248 - val_accuracy: 0.4375\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8026 - accuracy: 0.4456 - val_loss: 2.8236 - val_accuracy: 0.4367\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8025 - accuracy: 0.4461 - val_loss: 2.8225 - val_accuracy: 0.4361\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.8022 - accuracy: 0.4465 - val_loss: 2.8215 - val_accuracy: 0.4369\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.8015 - accuracy: 0.4454 - val_loss: 2.8206 - val_accuracy: 0.4369\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7993 - accuracy: 0.4471 - val_loss: 2.8196 - val_accuracy: 0.4375\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7985 - accuracy: 0.4463 - val_loss: 2.8191 - val_accuracy: 0.4389\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7968 - accuracy: 0.4470 - val_loss: 2.8180 - val_accuracy: 0.4385\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7973 - accuracy: 0.4473 - val_loss: 2.8169 - val_accuracy: 0.4385\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7952 - accuracy: 0.4475 - val_loss: 2.8155 - val_accuracy: 0.4379\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7940 - accuracy: 0.4489 - val_loss: 2.8151 - val_accuracy: 0.4390\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7933 - accuracy: 0.4490 - val_loss: 2.8139 - val_accuracy: 0.4394\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7923 - accuracy: 0.4479 - val_loss: 2.8129 - val_accuracy: 0.4391\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7900 - accuracy: 0.4500 - val_loss: 2.8121 - val_accuracy: 0.4401\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7900 - accuracy: 0.4494 - val_loss: 2.8109 - val_accuracy: 0.4404\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7896 - accuracy: 0.4494 - val_loss: 2.8100 - val_accuracy: 0.4402\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7900 - accuracy: 0.4487 - val_loss: 2.8093 - val_accuracy: 0.4410\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7891 - accuracy: 0.4496 - val_loss: 2.8082 - val_accuracy: 0.4406\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7868 - accuracy: 0.4506 - val_loss: 2.8082 - val_accuracy: 0.4402\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7889 - accuracy: 0.4476 - val_loss: 2.8081 - val_accuracy: 0.4412\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7868 - accuracy: 0.4521 - val_loss: 2.8082 - val_accuracy: 0.4410\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7872 - accuracy: 0.4502 - val_loss: 2.8079 - val_accuracy: 0.4419\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7871 - accuracy: 0.4497 - val_loss: 2.8079 - val_accuracy: 0.4414\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7867 - accuracy: 0.4496 - val_loss: 2.8076 - val_accuracy: 0.4409\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7867 - accuracy: 0.4493 - val_loss: 2.8077 - val_accuracy: 0.4418\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7860 - accuracy: 0.4516 - val_loss: 2.8077 - val_accuracy: 0.4413\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7884 - accuracy: 0.4495 - val_loss: 2.8077 - val_accuracy: 0.4411\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7873 - accuracy: 0.4499 - val_loss: 2.8076 - val_accuracy: 0.4408\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7880 - accuracy: 0.4498 - val_loss: 2.8074 - val_accuracy: 0.4410\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7858 - accuracy: 0.4499 - val_loss: 2.8075 - val_accuracy: 0.4407\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7873 - accuracy: 0.4519 - val_loss: 2.8073 - val_accuracy: 0.4415\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7861 - accuracy: 0.4522 - val_loss: 2.8075 - val_accuracy: 0.4416\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7855 - accuracy: 0.4521 - val_loss: 2.8071 - val_accuracy: 0.4402\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7862 - accuracy: 0.4526 - val_loss: 2.8072 - val_accuracy: 0.4413\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7857 - accuracy: 0.4508 - val_loss: 2.8072 - val_accuracy: 0.4417\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7854 - accuracy: 0.4509 - val_loss: 2.8069 - val_accuracy: 0.4407\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7861 - accuracy: 0.4502 - val_loss: 2.8068 - val_accuracy: 0.4411\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7859 - accuracy: 0.4511 - val_loss: 2.8067 - val_accuracy: 0.4410\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7862 - accuracy: 0.4513 - val_loss: 2.8068 - val_accuracy: 0.4415\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7860 - accuracy: 0.4489 - val_loss: 2.8065 - val_accuracy: 0.4407\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7856 - accuracy: 0.4511 - val_loss: 2.8064 - val_accuracy: 0.4408\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7850 - accuracy: 0.4508 - val_loss: 2.8066 - val_accuracy: 0.4410\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7855 - accuracy: 0.4496 - val_loss: 2.8062 - val_accuracy: 0.4413\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7865 - accuracy: 0.4510 - val_loss: 2.8064 - val_accuracy: 0.4410\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7837 - accuracy: 0.4514 - val_loss: 2.8062 - val_accuracy: 0.4423\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7842 - accuracy: 0.4532 - val_loss: 2.8061 - val_accuracy: 0.4412\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7858 - accuracy: 0.4502 - val_loss: 2.8062 - val_accuracy: 0.4415\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7864 - accuracy: 0.4494 - val_loss: 2.8059 - val_accuracy: 0.4410\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7846 - accuracy: 0.4516 - val_loss: 2.8058 - val_accuracy: 0.4420\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7842 - accuracy: 0.4517 - val_loss: 2.8061 - val_accuracy: 0.4421\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7859 - accuracy: 0.4509 - val_loss: 2.8057 - val_accuracy: 0.4417\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7860 - accuracy: 0.4512 - val_loss: 2.8064 - val_accuracy: 0.4417\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7841 - accuracy: 0.4505 - val_loss: 2.8059 - val_accuracy: 0.4414\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7840 - accuracy: 0.4497 - val_loss: 2.8059 - val_accuracy: 0.4420\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7842 - accuracy: 0.4497 - val_loss: 2.8058 - val_accuracy: 0.4418\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7855 - accuracy: 0.4506 - val_loss: 2.8059 - val_accuracy: 0.4414\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7852 - accuracy: 0.4505 - val_loss: 2.8059 - val_accuracy: 0.4410\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7845 - accuracy: 0.4517 - val_loss: 2.8059 - val_accuracy: 0.4417\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7831 - accuracy: 0.4522 - val_loss: 2.8060 - val_accuracy: 0.4407\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7840 - accuracy: 0.4529 - val_loss: 2.8061 - val_accuracy: 0.4409\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7843 - accuracy: 0.4518 - val_loss: 2.8060 - val_accuracy: 0.4419\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7850 - accuracy: 0.4539 - val_loss: 2.8060 - val_accuracy: 0.4410\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7840 - accuracy: 0.4505 - val_loss: 2.8059 - val_accuracy: 0.4414\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7840 - accuracy: 0.4505 - val_loss: 2.8060 - val_accuracy: 0.4422\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7835 - accuracy: 0.4531 - val_loss: 2.8061 - val_accuracy: 0.4414\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7857 - accuracy: 0.4504 - val_loss: 2.8059 - val_accuracy: 0.4414\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 108s 216ms/step - loss: 2.7840 - accuracy: 0.4521 - val_loss: 2.8062 - val_accuracy: 0.4417\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 108s 217ms/step - loss: 2.7849 - accuracy: 0.4507 - val_loss: 2.8061 - val_accuracy: 0.4412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0FyvZOoHKQf"
      },
      "source": [
        "#model.save('cifar10.simplenet2.h5')\n",
        "                 \n",
        "#model=load_model('cifar10_01.h5')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50eDgXQ7HQlZ",
        "outputId": "f414b2a6-57a3-4edf-b5b0-863fc4ed4e87"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "labels1 = np.arange(num_classes)\n",
        "print('Auc = %f' %  (roc_auc_score(y_test,  y_pred.round(),average='macro',multi_class='ovo',labels=labels1)))\n",
        "print('f1_score = %f' % (f1_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('precision = %f' % (precision_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('recall  = %f' % (recall_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('accuracy  = %f' % (accuracy_score(y_test, y_pred.round()))) "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc = 0.599039\n",
            "f1_score = 0.299960\n",
            "precision = 0.606805\n",
            "recall  = 0.211900\n",
            "accuracy  = 0.211900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "T7uXlIIsHVwX",
        "outputId": "0c0a47c6-295f-41f3-efe5-e7bb1eb1a5d1"
      },
      "source": [
        "plothist(history)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}