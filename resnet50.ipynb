{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAyFQoLwZJu8",
        "outputId": "7fb1c4e0-d5aa-4b7a-86d9-677450879afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls 'drive/My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            " bpm.behnejadi.rar\n",
            "'Colab Notebooks'\n",
            "'Copy of data.aug.rar'\n",
            " data.aug\n",
            " data.aug.rar\n",
            " data.mobilenet\n",
            " data.resnet50\n",
            " data.row\n",
            " dataset\n",
            " data.v\n",
            " data.vgg16\n",
            " data.xception\n",
            " IEEE_Iran_Section_Certificate_AIDLinAutoRobotics__Fateme_behnejadi__125598.pdf\n",
            " thesis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ESUWX_ZNqD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0fl8YlGZNeb"
      },
      "source": [
        "train_path = '/content/drive/My Drive/data.resnet50/tc-ts/train'\n",
        "valid_path = '/content/drive/My Drive/data.resnet50/tc-ts/valid'\n",
        "test_path = '/content/drive/My Drive/data.resnet50/tc-ts/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_BCOOXZNWS",
        "outputId": "26426c0a-4fe9-4742-b9d4-4cb99af99f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input ) \\\n",
        "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['TS', 'TC'], batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input ) \\\n",
        "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['TS', 'TC'], batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input ) \\\n",
        "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['TS', 'TC'], batch_size=10, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2093 images belonging to 2 classes.\n",
            "Found 90 images belonging to 2 classes.\n",
            "Found 95 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo_Uj8cjZNTE",
        "outputId": "c9599ad1-d6e8-4058-c00b-5dd60214056a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet50 = tf.keras.applications.ResNet50() \n",
        "resnet50.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 3s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qy5h2dZNNz"
      },
      "source": [
        "x = resnet50.layers[-2].output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0niV2DoRZNLf"
      },
      "source": [
        "output = Dense(units=2, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzG0MP68ZNJD"
      },
      "source": [
        "model = Model(inputs=resnet50.input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFARn69XZNGR",
        "outputId": "597b0786-059f-4365-b9f2-d4ee37757291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#for layer in model.layers[:-23]:\n",
        "#   layer.trainable = False\n",
        "\n",
        "for layer in model.layers[175:]:\n",
        "    layer.trainable = True\n",
        "for layer in model.layers[:175]:\n",
        "    layer.trainable = False\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 conv1_pad False\n",
            "2 conv1_conv False\n",
            "3 conv1_bn False\n",
            "4 conv1_relu False\n",
            "5 pool1_pad False\n",
            "6 pool1_pool False\n",
            "7 conv2_block1_1_conv False\n",
            "8 conv2_block1_1_bn False\n",
            "9 conv2_block1_1_relu False\n",
            "10 conv2_block1_2_conv False\n",
            "11 conv2_block1_2_bn False\n",
            "12 conv2_block1_2_relu False\n",
            "13 conv2_block1_0_conv False\n",
            "14 conv2_block1_3_conv False\n",
            "15 conv2_block1_0_bn False\n",
            "16 conv2_block1_3_bn False\n",
            "17 conv2_block1_add False\n",
            "18 conv2_block1_out False\n",
            "19 conv2_block2_1_conv False\n",
            "20 conv2_block2_1_bn False\n",
            "21 conv2_block2_1_relu False\n",
            "22 conv2_block2_2_conv False\n",
            "23 conv2_block2_2_bn False\n",
            "24 conv2_block2_2_relu False\n",
            "25 conv2_block2_3_conv False\n",
            "26 conv2_block2_3_bn False\n",
            "27 conv2_block2_add False\n",
            "28 conv2_block2_out False\n",
            "29 conv2_block3_1_conv False\n",
            "30 conv2_block3_1_bn False\n",
            "31 conv2_block3_1_relu False\n",
            "32 conv2_block3_2_conv False\n",
            "33 conv2_block3_2_bn False\n",
            "34 conv2_block3_2_relu False\n",
            "35 conv2_block3_3_conv False\n",
            "36 conv2_block3_3_bn False\n",
            "37 conv2_block3_add False\n",
            "38 conv2_block3_out False\n",
            "39 conv3_block1_1_conv False\n",
            "40 conv3_block1_1_bn False\n",
            "41 conv3_block1_1_relu False\n",
            "42 conv3_block1_2_conv False\n",
            "43 conv3_block1_2_bn False\n",
            "44 conv3_block1_2_relu False\n",
            "45 conv3_block1_0_conv False\n",
            "46 conv3_block1_3_conv False\n",
            "47 conv3_block1_0_bn False\n",
            "48 conv3_block1_3_bn False\n",
            "49 conv3_block1_add False\n",
            "50 conv3_block1_out False\n",
            "51 conv3_block2_1_conv False\n",
            "52 conv3_block2_1_bn False\n",
            "53 conv3_block2_1_relu False\n",
            "54 conv3_block2_2_conv False\n",
            "55 conv3_block2_2_bn False\n",
            "56 conv3_block2_2_relu False\n",
            "57 conv3_block2_3_conv False\n",
            "58 conv3_block2_3_bn False\n",
            "59 conv3_block2_add False\n",
            "60 conv3_block2_out False\n",
            "61 conv3_block3_1_conv False\n",
            "62 conv3_block3_1_bn False\n",
            "63 conv3_block3_1_relu False\n",
            "64 conv3_block3_2_conv False\n",
            "65 conv3_block3_2_bn False\n",
            "66 conv3_block3_2_relu False\n",
            "67 conv3_block3_3_conv False\n",
            "68 conv3_block3_3_bn False\n",
            "69 conv3_block3_add False\n",
            "70 conv3_block3_out False\n",
            "71 conv3_block4_1_conv False\n",
            "72 conv3_block4_1_bn False\n",
            "73 conv3_block4_1_relu False\n",
            "74 conv3_block4_2_conv False\n",
            "75 conv3_block4_2_bn False\n",
            "76 conv3_block4_2_relu False\n",
            "77 conv3_block4_3_conv False\n",
            "78 conv3_block4_3_bn False\n",
            "79 conv3_block4_add False\n",
            "80 conv3_block4_out False\n",
            "81 conv4_block1_1_conv False\n",
            "82 conv4_block1_1_bn False\n",
            "83 conv4_block1_1_relu False\n",
            "84 conv4_block1_2_conv False\n",
            "85 conv4_block1_2_bn False\n",
            "86 conv4_block1_2_relu False\n",
            "87 conv4_block1_0_conv False\n",
            "88 conv4_block1_3_conv False\n",
            "89 conv4_block1_0_bn False\n",
            "90 conv4_block1_3_bn False\n",
            "91 conv4_block1_add False\n",
            "92 conv4_block1_out False\n",
            "93 conv4_block2_1_conv False\n",
            "94 conv4_block2_1_bn False\n",
            "95 conv4_block2_1_relu False\n",
            "96 conv4_block2_2_conv False\n",
            "97 conv4_block2_2_bn False\n",
            "98 conv4_block2_2_relu False\n",
            "99 conv4_block2_3_conv False\n",
            "100 conv4_block2_3_bn False\n",
            "101 conv4_block2_add False\n",
            "102 conv4_block2_out False\n",
            "103 conv4_block3_1_conv False\n",
            "104 conv4_block3_1_bn False\n",
            "105 conv4_block3_1_relu False\n",
            "106 conv4_block3_2_conv False\n",
            "107 conv4_block3_2_bn False\n",
            "108 conv4_block3_2_relu False\n",
            "109 conv4_block3_3_conv False\n",
            "110 conv4_block3_3_bn False\n",
            "111 conv4_block3_add False\n",
            "112 conv4_block3_out False\n",
            "113 conv4_block4_1_conv False\n",
            "114 conv4_block4_1_bn False\n",
            "115 conv4_block4_1_relu False\n",
            "116 conv4_block4_2_conv False\n",
            "117 conv4_block4_2_bn False\n",
            "118 conv4_block4_2_relu False\n",
            "119 conv4_block4_3_conv False\n",
            "120 conv4_block4_3_bn False\n",
            "121 conv4_block4_add False\n",
            "122 conv4_block4_out False\n",
            "123 conv4_block5_1_conv False\n",
            "124 conv4_block5_1_bn False\n",
            "125 conv4_block5_1_relu False\n",
            "126 conv4_block5_2_conv False\n",
            "127 conv4_block5_2_bn False\n",
            "128 conv4_block5_2_relu False\n",
            "129 conv4_block5_3_conv False\n",
            "130 conv4_block5_3_bn False\n",
            "131 conv4_block5_add False\n",
            "132 conv4_block5_out False\n",
            "133 conv4_block6_1_conv False\n",
            "134 conv4_block6_1_bn False\n",
            "135 conv4_block6_1_relu False\n",
            "136 conv4_block6_2_conv False\n",
            "137 conv4_block6_2_bn False\n",
            "138 conv4_block6_2_relu False\n",
            "139 conv4_block6_3_conv False\n",
            "140 conv4_block6_3_bn False\n",
            "141 conv4_block6_add False\n",
            "142 conv4_block6_out False\n",
            "143 conv5_block1_1_conv False\n",
            "144 conv5_block1_1_bn False\n",
            "145 conv5_block1_1_relu False\n",
            "146 conv5_block1_2_conv False\n",
            "147 conv5_block1_2_bn False\n",
            "148 conv5_block1_2_relu False\n",
            "149 conv5_block1_0_conv False\n",
            "150 conv5_block1_3_conv False\n",
            "151 conv5_block1_0_bn False\n",
            "152 conv5_block1_3_bn False\n",
            "153 conv5_block1_add False\n",
            "154 conv5_block1_out False\n",
            "155 conv5_block2_1_conv False\n",
            "156 conv5_block2_1_bn False\n",
            "157 conv5_block2_1_relu False\n",
            "158 conv5_block2_2_conv False\n",
            "159 conv5_block2_2_bn False\n",
            "160 conv5_block2_2_relu False\n",
            "161 conv5_block2_3_conv False\n",
            "162 conv5_block2_3_bn False\n",
            "163 conv5_block2_add False\n",
            "164 conv5_block2_out False\n",
            "165 conv5_block3_1_conv False\n",
            "166 conv5_block3_1_bn False\n",
            "167 conv5_block3_1_relu False\n",
            "168 conv5_block3_2_conv False\n",
            "169 conv5_block3_2_bn False\n",
            "170 conv5_block3_2_relu False\n",
            "171 conv5_block3_3_conv False\n",
            "172 conv5_block3_3_bn False\n",
            "173 conv5_block3_add False\n",
            "174 conv5_block3_out False\n",
            "175 avg_pool True\n",
            "176 dense True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtTrzDGTZNDX"
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1zKlRQ4ZNAr",
        "outputId": "a16a47a9-83a8-4214-8a80-c6305f3cf710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=train_batches,\n",
        "            steps_per_epoch=len(train_batches),\n",
        "            validation_data=valid_batches,\n",
        "            validation_steps=len(valid_batches),\n",
        "            epochs=100,\n",
        "            verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 - 904s - loss: 0.6912 - accuracy: 0.6331 - val_loss: 0.6537 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "210/210 - 14s - loss: 0.5454 - accuracy: 0.7339 - val_loss: 0.5896 - val_accuracy: 0.6778\n",
            "Epoch 3/100\n",
            "210/210 - 14s - loss: 0.5167 - accuracy: 0.7468 - val_loss: 0.5642 - val_accuracy: 0.7222\n",
            "Epoch 4/100\n",
            "210/210 - 14s - loss: 0.4969 - accuracy: 0.7587 - val_loss: 0.5567 - val_accuracy: 0.7222\n",
            "Epoch 5/100\n",
            "210/210 - 14s - loss: 0.4811 - accuracy: 0.7678 - val_loss: 0.5462 - val_accuracy: 0.7333\n",
            "Epoch 6/100\n",
            "210/210 - 14s - loss: 0.4661 - accuracy: 0.7702 - val_loss: 0.5332 - val_accuracy: 0.7333\n",
            "Epoch 7/100\n",
            "210/210 - 14s - loss: 0.4549 - accuracy: 0.7807 - val_loss: 0.5424 - val_accuracy: 0.7667\n",
            "Epoch 8/100\n",
            "210/210 - 14s - loss: 0.4432 - accuracy: 0.7817 - val_loss: 0.5273 - val_accuracy: 0.7556\n",
            "Epoch 9/100\n",
            "210/210 - 14s - loss: 0.4362 - accuracy: 0.7864 - val_loss: 0.5423 - val_accuracy: 0.7556\n",
            "Epoch 10/100\n",
            "210/210 - 13s - loss: 0.4265 - accuracy: 0.7974 - val_loss: 0.5374 - val_accuracy: 0.7556\n",
            "Epoch 11/100\n",
            "210/210 - 14s - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5443 - val_accuracy: 0.7556\n",
            "Epoch 12/100\n",
            "210/210 - 14s - loss: 0.4148 - accuracy: 0.8055 - val_loss: 0.5499 - val_accuracy: 0.7556\n",
            "Epoch 13/100\n",
            "210/210 - 13s - loss: 0.4067 - accuracy: 0.8161 - val_loss: 0.5457 - val_accuracy: 0.7556\n",
            "Epoch 14/100\n",
            "210/210 - 13s - loss: 0.4013 - accuracy: 0.8132 - val_loss: 0.5511 - val_accuracy: 0.7556\n",
            "Epoch 15/100\n",
            "210/210 - 13s - loss: 0.3933 - accuracy: 0.8232 - val_loss: 0.5345 - val_accuracy: 0.7444\n",
            "Epoch 16/100\n",
            "210/210 - 13s - loss: 0.3886 - accuracy: 0.8232 - val_loss: 0.5326 - val_accuracy: 0.7444\n",
            "Epoch 17/100\n",
            "210/210 - 13s - loss: 0.3814 - accuracy: 0.8352 - val_loss: 0.5389 - val_accuracy: 0.7444\n",
            "Epoch 18/100\n",
            "210/210 - 13s - loss: 0.3789 - accuracy: 0.8318 - val_loss: 0.5383 - val_accuracy: 0.7667\n",
            "Epoch 19/100\n",
            "210/210 - 13s - loss: 0.3728 - accuracy: 0.8423 - val_loss: 0.5526 - val_accuracy: 0.7778\n",
            "Epoch 20/100\n",
            "210/210 - 13s - loss: 0.3669 - accuracy: 0.8452 - val_loss: 0.5319 - val_accuracy: 0.7556\n",
            "Epoch 21/100\n",
            "210/210 - 13s - loss: 0.3673 - accuracy: 0.8356 - val_loss: 0.5464 - val_accuracy: 0.7778\n",
            "Epoch 22/100\n",
            "210/210 - 13s - loss: 0.3625 - accuracy: 0.8376 - val_loss: 0.5353 - val_accuracy: 0.7778\n",
            "Epoch 23/100\n",
            "210/210 - 13s - loss: 0.3566 - accuracy: 0.8495 - val_loss: 0.5789 - val_accuracy: 0.6778\n",
            "Epoch 24/100\n",
            "210/210 - 13s - loss: 0.3508 - accuracy: 0.8562 - val_loss: 0.5276 - val_accuracy: 0.7889\n",
            "Epoch 25/100\n",
            "210/210 - 13s - loss: 0.3488 - accuracy: 0.8509 - val_loss: 0.5298 - val_accuracy: 0.7889\n",
            "Epoch 26/100\n",
            "210/210 - 13s - loss: 0.3438 - accuracy: 0.8576 - val_loss: 0.5248 - val_accuracy: 0.7444\n",
            "Epoch 27/100\n",
            "210/210 - 13s - loss: 0.3411 - accuracy: 0.8605 - val_loss: 0.5318 - val_accuracy: 0.8000\n",
            "Epoch 28/100\n",
            "210/210 - 13s - loss: 0.3360 - accuracy: 0.8681 - val_loss: 0.5505 - val_accuracy: 0.7889\n",
            "Epoch 29/100\n",
            "210/210 - 14s - loss: 0.3331 - accuracy: 0.8634 - val_loss: 0.5488 - val_accuracy: 0.7889\n",
            "Epoch 30/100\n",
            "210/210 - 13s - loss: 0.3291 - accuracy: 0.8643 - val_loss: 0.5339 - val_accuracy: 0.7889\n",
            "Epoch 31/100\n",
            "210/210 - 13s - loss: 0.3279 - accuracy: 0.8715 - val_loss: 0.5337 - val_accuracy: 0.7889\n",
            "Epoch 32/100\n",
            "210/210 - 13s - loss: 0.3238 - accuracy: 0.8729 - val_loss: 0.5522 - val_accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "210/210 - 13s - loss: 0.3189 - accuracy: 0.8681 - val_loss: 0.5626 - val_accuracy: 0.7556\n",
            "Epoch 34/100\n",
            "210/210 - 13s - loss: 0.3178 - accuracy: 0.8729 - val_loss: 0.5385 - val_accuracy: 0.8111\n",
            "Epoch 35/100\n",
            "210/210 - 13s - loss: 0.3146 - accuracy: 0.8720 - val_loss: 0.5585 - val_accuracy: 0.7556\n",
            "Epoch 36/100\n",
            "210/210 - 13s - loss: 0.3118 - accuracy: 0.8810 - val_loss: 0.5331 - val_accuracy: 0.7778\n",
            "Epoch 37/100\n",
            "210/210 - 14s - loss: 0.3076 - accuracy: 0.8796 - val_loss: 0.5863 - val_accuracy: 0.7111\n",
            "Epoch 38/100\n",
            "210/210 - 14s - loss: 0.3051 - accuracy: 0.8858 - val_loss: 0.5390 - val_accuracy: 0.8111\n",
            "Epoch 39/100\n",
            "210/210 - 14s - loss: 0.3033 - accuracy: 0.8877 - val_loss: 0.5321 - val_accuracy: 0.7667\n",
            "Epoch 40/100\n",
            "210/210 - 14s - loss: 0.2977 - accuracy: 0.8915 - val_loss: 0.5286 - val_accuracy: 0.7556\n",
            "Epoch 41/100\n",
            "210/210 - 14s - loss: 0.2979 - accuracy: 0.8911 - val_loss: 0.5552 - val_accuracy: 0.8000\n",
            "Epoch 42/100\n",
            "210/210 - 14s - loss: 0.2945 - accuracy: 0.8863 - val_loss: 0.5481 - val_accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "210/210 - 14s - loss: 0.2928 - accuracy: 0.8868 - val_loss: 0.5400 - val_accuracy: 0.8111\n",
            "Epoch 44/100\n",
            "210/210 - 14s - loss: 0.2897 - accuracy: 0.8915 - val_loss: 0.5680 - val_accuracy: 0.7556\n",
            "Epoch 45/100\n",
            "210/210 - 14s - loss: 0.2883 - accuracy: 0.8901 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
            "Epoch 46/100\n",
            "210/210 - 14s - loss: 0.2855 - accuracy: 0.8963 - val_loss: 0.5351 - val_accuracy: 0.7889\n",
            "Epoch 47/100\n",
            "210/210 - 14s - loss: 0.2811 - accuracy: 0.9016 - val_loss: 0.5283 - val_accuracy: 0.7778\n",
            "Epoch 48/100\n",
            "210/210 - 14s - loss: 0.2798 - accuracy: 0.8997 - val_loss: 0.5488 - val_accuracy: 0.8111\n",
            "Epoch 49/100\n",
            "210/210 - 14s - loss: 0.2787 - accuracy: 0.8930 - val_loss: 0.5486 - val_accuracy: 0.8111\n",
            "Epoch 50/100\n",
            "210/210 - 14s - loss: 0.2745 - accuracy: 0.9011 - val_loss: 0.5519 - val_accuracy: 0.8111\n",
            "Epoch 51/100\n",
            "210/210 - 14s - loss: 0.2730 - accuracy: 0.9001 - val_loss: 0.5470 - val_accuracy: 0.7889\n",
            "Epoch 52/100\n",
            "210/210 - 14s - loss: 0.2708 - accuracy: 0.8997 - val_loss: 0.5438 - val_accuracy: 0.7889\n",
            "Epoch 53/100\n",
            "210/210 - 13s - loss: 0.2699 - accuracy: 0.9049 - val_loss: 0.5524 - val_accuracy: 0.8111\n",
            "Epoch 54/100\n",
            "210/210 - 14s - loss: 0.2683 - accuracy: 0.9035 - val_loss: 0.5396 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "210/210 - 13s - loss: 0.2643 - accuracy: 0.9107 - val_loss: 0.5411 - val_accuracy: 0.7889\n",
            "Epoch 56/100\n",
            "210/210 - 13s - loss: 0.2625 - accuracy: 0.9116 - val_loss: 0.5444 - val_accuracy: 0.8000\n",
            "Epoch 57/100\n",
            "210/210 - 13s - loss: 0.2600 - accuracy: 0.9116 - val_loss: 0.5333 - val_accuracy: 0.7889\n",
            "Epoch 58/100\n",
            "210/210 - 13s - loss: 0.2611 - accuracy: 0.9035 - val_loss: 0.5408 - val_accuracy: 0.7778\n",
            "Epoch 59/100\n",
            "210/210 - 13s - loss: 0.2563 - accuracy: 0.9130 - val_loss: 0.5399 - val_accuracy: 0.7889\n",
            "Epoch 60/100\n",
            "210/210 - 14s - loss: 0.2548 - accuracy: 0.9111 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "210/210 - 13s - loss: 0.2524 - accuracy: 0.9164 - val_loss: 0.5581 - val_accuracy: 0.7778\n",
            "Epoch 62/100\n",
            "210/210 - 13s - loss: 0.2516 - accuracy: 0.9130 - val_loss: 0.5426 - val_accuracy: 0.7889\n",
            "Epoch 63/100\n",
            "210/210 - 13s - loss: 0.2484 - accuracy: 0.9150 - val_loss: 0.5380 - val_accuracy: 0.7889\n",
            "Epoch 64/100\n",
            "210/210 - 13s - loss: 0.2470 - accuracy: 0.9169 - val_loss: 0.5623 - val_accuracy: 0.8000\n",
            "Epoch 65/100\n",
            "210/210 - 13s - loss: 0.2446 - accuracy: 0.9197 - val_loss: 0.5419 - val_accuracy: 0.7889\n",
            "Epoch 66/100\n",
            "210/210 - 13s - loss: 0.2440 - accuracy: 0.9178 - val_loss: 0.5514 - val_accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "210/210 - 13s - loss: 0.2435 - accuracy: 0.9145 - val_loss: 0.5546 - val_accuracy: 0.7889\n",
            "Epoch 68/100\n",
            "210/210 - 13s - loss: 0.2403 - accuracy: 0.9236 - val_loss: 0.5724 - val_accuracy: 0.7778\n",
            "Epoch 69/100\n",
            "210/210 - 13s - loss: 0.2397 - accuracy: 0.9216 - val_loss: 0.5951 - val_accuracy: 0.7444\n",
            "Epoch 70/100\n",
            "210/210 - 13s - loss: 0.2380 - accuracy: 0.9250 - val_loss: 0.5609 - val_accuracy: 0.7778\n",
            "Epoch 71/100\n",
            "210/210 - 13s - loss: 0.2349 - accuracy: 0.9221 - val_loss: 0.5406 - val_accuracy: 0.8000\n",
            "Epoch 72/100\n",
            "210/210 - 13s - loss: 0.2365 - accuracy: 0.9188 - val_loss: 0.5676 - val_accuracy: 0.7667\n",
            "Epoch 73/100\n",
            "210/210 - 13s - loss: 0.2307 - accuracy: 0.9216 - val_loss: 0.5425 - val_accuracy: 0.7889\n",
            "Epoch 74/100\n",
            "210/210 - 13s - loss: 0.2318 - accuracy: 0.9259 - val_loss: 0.5612 - val_accuracy: 0.7778\n",
            "Epoch 75/100\n",
            "210/210 - 14s - loss: 0.2285 - accuracy: 0.9245 - val_loss: 0.5836 - val_accuracy: 0.7667\n",
            "Epoch 76/100\n",
            "210/210 - 13s - loss: 0.2277 - accuracy: 0.9274 - val_loss: 0.5675 - val_accuracy: 0.7778\n",
            "Epoch 77/100\n",
            "210/210 - 13s - loss: 0.2243 - accuracy: 0.9312 - val_loss: 0.5631 - val_accuracy: 0.7889\n",
            "Epoch 78/100\n",
            "210/210 - 13s - loss: 0.2240 - accuracy: 0.9312 - val_loss: 0.5567 - val_accuracy: 0.8000\n",
            "Epoch 79/100\n",
            "210/210 - 13s - loss: 0.2223 - accuracy: 0.9360 - val_loss: 0.5833 - val_accuracy: 0.7778\n",
            "Epoch 80/100\n",
            "210/210 - 13s - loss: 0.2212 - accuracy: 0.9255 - val_loss: 0.5484 - val_accuracy: 0.7778\n",
            "Epoch 81/100\n",
            "210/210 - 13s - loss: 0.2208 - accuracy: 0.9274 - val_loss: 0.5448 - val_accuracy: 0.7889\n",
            "Epoch 82/100\n",
            "210/210 - 13s - loss: 0.2168 - accuracy: 0.9326 - val_loss: 0.5490 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "210/210 - 13s - loss: 0.2172 - accuracy: 0.9322 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "210/210 - 13s - loss: 0.2153 - accuracy: 0.9355 - val_loss: 0.5517 - val_accuracy: 0.7778\n",
            "Epoch 85/100\n",
            "210/210 - 13s - loss: 0.2133 - accuracy: 0.9360 - val_loss: 0.5770 - val_accuracy: 0.7556\n",
            "Epoch 86/100\n",
            "210/210 - 13s - loss: 0.2128 - accuracy: 0.9360 - val_loss: 0.5420 - val_accuracy: 0.8222\n",
            "Epoch 87/100\n",
            "210/210 - 13s - loss: 0.2121 - accuracy: 0.9326 - val_loss: 0.5591 - val_accuracy: 0.7889\n",
            "Epoch 88/100\n",
            "210/210 - 13s - loss: 0.2108 - accuracy: 0.9388 - val_loss: 0.5671 - val_accuracy: 0.7778\n",
            "Epoch 89/100\n",
            "210/210 - 13s - loss: 0.2075 - accuracy: 0.9345 - val_loss: 0.5510 - val_accuracy: 0.7889\n",
            "Epoch 90/100\n",
            "210/210 - 13s - loss: 0.2081 - accuracy: 0.9350 - val_loss: 0.5662 - val_accuracy: 0.7778\n",
            "Epoch 91/100\n",
            "210/210 - 13s - loss: 0.2054 - accuracy: 0.9365 - val_loss: 0.5531 - val_accuracy: 0.7889\n",
            "Epoch 92/100\n",
            "210/210 - 13s - loss: 0.2050 - accuracy: 0.9379 - val_loss: 0.5476 - val_accuracy: 0.8111\n",
            "Epoch 93/100\n",
            "210/210 - 13s - loss: 0.2038 - accuracy: 0.9403 - val_loss: 0.5508 - val_accuracy: 0.8111\n",
            "Epoch 94/100\n",
            "210/210 - 13s - loss: 0.2017 - accuracy: 0.9422 - val_loss: 0.5655 - val_accuracy: 0.7889\n",
            "Epoch 95/100\n",
            "210/210 - 13s - loss: 0.2008 - accuracy: 0.9388 - val_loss: 0.5821 - val_accuracy: 0.7556\n",
            "Epoch 96/100\n",
            "210/210 - 13s - loss: 0.2000 - accuracy: 0.9465 - val_loss: 0.5837 - val_accuracy: 0.7667\n",
            "Epoch 97/100\n",
            "210/210 - 13s - loss: 0.1970 - accuracy: 0.9408 - val_loss: 0.5519 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "210/210 - 14s - loss: 0.1983 - accuracy: 0.9408 - val_loss: 0.5671 - val_accuracy: 0.7889\n",
            "Epoch 99/100\n",
            "210/210 - 13s - loss: 0.1969 - accuracy: 0.9412 - val_loss: 0.5620 - val_accuracy: 0.7889\n",
            "Epoch 100/100\n",
            "210/210 - 13s - loss: 0.1941 - accuracy: 0.9427 - val_loss: 0.5623 - val_accuracy: 0.7889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07b5960080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwOZgyay9bvl"
      },
      "source": [
        "#for layer in model.layers[165:]:\n",
        "    layer.trainable = True\n",
        "#for layer in model.layers[:165]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOazUtPG9bgf"
      },
      "source": [
        "#model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnB8X0cr_hwQ",
        "outputId": "ac7a4f15-71c7-4794-e95c-dc422d7cf116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model.fit(x=train_batches,\n",
        "           # steps_per_epoch=len(train_batches),\n",
        "           # validation_data=valid_batches,\n",
        "           # validation_steps=len(valid_batches),\n",
        "           # epochs=100,\n",
        "           # verbose=2\n",
        "#)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 - 16s - loss: 1.8974e-06 - accuracy: 1.0000 - val_loss: 1.6747 - val_accuracy: 0.6556\n",
            "Epoch 2/100\n",
            "210/210 - 15s - loss: 1.1349e-06 - accuracy: 1.0000 - val_loss: 1.7371 - val_accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "210/210 - 15s - loss: 8.8047e-07 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.6667\n",
            "Epoch 4/100\n",
            "210/210 - 15s - loss: 5.4666e-07 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "210/210 - 15s - loss: 4.0017e-07 - accuracy: 1.0000 - val_loss: 1.8723 - val_accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "210/210 - 15s - loss: 3.0806e-06 - accuracy: 1.0000 - val_loss: 1.8179 - val_accuracy: 0.6222\n",
            "Epoch 7/100\n",
            "210/210 - 15s - loss: 2.8249e-06 - accuracy: 1.0000 - val_loss: 1.8884 - val_accuracy: 0.6667\n",
            "Epoch 8/100\n",
            "210/210 - 15s - loss: 5.2439e-07 - accuracy: 1.0000 - val_loss: 1.8939 - val_accuracy: 0.6667\n",
            "Epoch 9/100\n",
            "210/210 - 15s - loss: 4.7683e-07 - accuracy: 1.0000 - val_loss: 1.9007 - val_accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "210/210 - 15s - loss: 3.2459e-07 - accuracy: 1.0000 - val_loss: 1.9114 - val_accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "210/210 - 15s - loss: 2.6023e-07 - accuracy: 1.0000 - val_loss: 1.9287 - val_accuracy: 0.6667\n",
            "Epoch 12/100\n",
            "210/210 - 15s - loss: 2.7806e-07 - accuracy: 1.0000 - val_loss: 1.9429 - val_accuracy: 0.6778\n",
            "Epoch 13/100\n",
            "210/210 - 15s - loss: 2.2144e-07 - accuracy: 1.0000 - val_loss: 1.9553 - val_accuracy: 0.6889\n",
            "Epoch 14/100\n",
            "210/210 - 15s - loss: 2.1376e-07 - accuracy: 1.0000 - val_loss: 1.9722 - val_accuracy: 0.6889\n",
            "Epoch 15/100\n",
            "210/210 - 15s - loss: 1.6324e-07 - accuracy: 1.0000 - val_loss: 1.9943 - val_accuracy: 0.6889\n",
            "Epoch 16/100\n",
            "210/210 - 15s - loss: 1.5788e-07 - accuracy: 1.0000 - val_loss: 2.0068 - val_accuracy: 0.6889\n",
            "Epoch 17/100\n",
            "210/210 - 14s - loss: 1.4307e-07 - accuracy: 1.0000 - val_loss: 2.0267 - val_accuracy: 0.6889\n",
            "Epoch 18/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-18-41cb37d9e2e6>\", line 6, in <module>\n",
            "    verbose=2\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\n",
            "    tmp_logs = train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkbaDnZKZM5B"
      },
      "source": [
        "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTkb0niOZM10",
        "outputId": "2c29ddb5-3799-4103-a255-17b8b9215907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "np.round(predictions)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt-1iEN3ZMzb"
      },
      "source": [
        "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE3JJuMCZMwt"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Odu1NfSZMtk",
        "outputId": "e3f7a855-6be8-41ae-ffaf-2bca8eaadb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_batches.class_indices"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'TC': 1, 'TS': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahmyC7njZMqU",
        "outputId": "383a9fdd-bce1-4b79-964e-be82fadbdc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "cm_plot_labels = ['TS','TC']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[25 10]\n",
            " [13 47]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}