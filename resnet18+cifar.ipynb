{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18+cifar10_(6)_(2) (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ESUWX_ZNqD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense, Activation ,AveragePooling2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc,precision_score, recall_score,f1_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy import interp\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "import scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Lambda, Input\n",
        "from keras.models import Model, Sequential\n",
        "import tensorflow as ktf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYG194TF_w9d",
        "outputId": "44d79c8d-7bb4-4695-8566-5dae6d3a9973"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('Train data shape: {}'.format(X_train.shape))\n",
        "print('Test  data shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "Train data shape: (50000, 32, 32, 3)\n",
            "Test  data shape: (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y68QeKy_EIn5"
      },
      "source": [
        "image_size = 32\n",
        "num_channels = 3\n",
        "num_features = image_size * image_size * num_channels\n",
        "num_classes = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grGv0zltDvh5",
        "outputId": "38090b7c-3469-49a2-dc24-556ec0ad9b72"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "x_test  = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255.0\n",
        "mean = np.mean(X_train, axis=(0, 1, 2,3))\n",
        "std = np.std(X_train, axis=(0, 1, 2,3))\n",
        "X_train = (X_train - mean)/ (std+1e-7)\n",
        "\n",
        "x_test /= 255.0\n",
        "\n",
        "x_test =(x_test-mean) / (std+1e-7)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(x_test.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGctKnwPDvXT",
        "outputId": "2b092f8a-c273-41f6-857b-63994ed45197"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwZZdax7GjhE"
      },
      "source": [
        "# plotting helper function\n",
        "def plothist(hist):\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(hist.history['accuracy'])\n",
        "    plt.plot(hist.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUs8Of18sIiP",
        "outputId": "53a5bed2-cefc-4e19-fe9a-dbbfe981a068"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-m7du4tur\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-m7du4tur\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.15.0)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-cp36-none-any.whl size=20031 sha256=1f875b133ac6385efda4f1daa449a179c518ceb57b2431219be88d3d145869f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b9aof4g7/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhgtSsJFsif"
      },
      "source": [
        "from classification_models.tfkeras import Classifiers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo_Uj8cjZNTE",
        "outputId": "f491eeb3-014e-4cf8-8223-ebd6edbabef8"
      },
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "resnet18 = ResNet18((224, 224, 3), weights='imagenet')\n",
        "resnet18.summary() "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000.h5\n",
            "46981120/46977688 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 224, 224, 3)  9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 112, 112, 64) 256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 112, 112, 64) 0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 56, 56, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 56, 56, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 58, 58, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 56, 56, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 56, 56, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 58, 58, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 56, 56, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 56, 56, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 56, 56, 64)   256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 56, 56, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 58, 58, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 56, 56, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 56, 56, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 58, 58, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 56, 56, 64)   36864       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 56, 56, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 56, 56, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 58, 58, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 28, 28, 128)  73728       zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 28, 28, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 28, 28, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 30, 30, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 28, 28, 128)  147456      zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 28, 28, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 28, 28, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 28, 28, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 28, 28, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 30, 30, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 28, 28, 128)  147456      zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 28, 28, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 28, 28, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 30, 30, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 28, 28, 128)  147456      zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 28, 28, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 28, 28, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 30, 30, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 14, 14, 256)  294912      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 14, 14, 256)  1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 14, 14, 256)  0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 16, 16, 256)  0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 14, 14, 256)  589824      zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 14, 14, 256)  32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 256)  0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 14, 14, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, 14, 14, 256)  0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 256)  0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, 14, 14, 256)  589824      zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, 14, 14, 256)  1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, 14, 14, 256)  0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, 16, 16, 256)  0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, 14, 14, 256)  589824      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 14, 14, 256)  0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, 14, 14, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, 14, 14, 256)  0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 16, 16, 256)  0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, 7, 7, 512)    1179648     zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, 7, 7, 512)    2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, 7, 7, 512)    0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, 9, 9, 512)    0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, 7, 7, 512)    2359296     zero_padding2d_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, 7, 7, 512)    131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 7, 7, 512)    0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, 7, 7, 512)    2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, 7, 7, 512)    0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, 9, 9, 512)    0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, 7, 7, 512)    2359296     zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, 7, 7, 512)    2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, 7, 7, 512)    0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, 9, 9, 512)    0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, 7, 7, 512)    2359296     zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 7, 7, 512)    0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 7, 7, 512)    2048        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 7, 7, 512)    0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (GlobalAveragePooling2D)  (None, 512)          0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 1000)         513000      pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 1000)         0           fc1[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 11,699,889\n",
            "Trainable params: 11,691,947\n",
            "Non-trainable params: 7,942\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tebKLPNJmVD"
      },
      "source": [
        "alpha = 0.003  # weight decay coefficient\n",
        "\n",
        "for layer in resnet18.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "        layer.add_loss(lambda: keras.regularizers.l2(alpha)(layer.kernel))\n",
        "    if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "        layer.add_loss(lambda: keras.regularizers.l2(alpha)(layer.bias))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qy5h2dZNNz"
      },
      "source": [
        "x = resnet18.layers[-2].output\r\n",
        "output = Dense(units=10,activation='softmax')(x)\r\n",
        "model = Model(inputs=[resnet18.input], outputs=[output])\r\n",
        "#model.summary()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFARn69XZNGR",
        "outputId": "fdbff379-2d0d-4e77-df2b-bd4d656a9664"
      },
      "source": [
        "for layer in model.layers[35:]:\n",
        "    layer.trainable = True\n",
        "for layer in model.layers[:35]:\n",
        "    layer.trainable = False\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 data False\n",
            "1 bn_data False\n",
            "2 zero_padding2d False\n",
            "3 conv0 False\n",
            "4 bn0 False\n",
            "5 relu0 False\n",
            "6 zero_padding2d_1 False\n",
            "7 pooling0 False\n",
            "8 stage1_unit1_bn1 False\n",
            "9 stage1_unit1_relu1 False\n",
            "10 zero_padding2d_2 False\n",
            "11 stage1_unit1_conv1 False\n",
            "12 stage1_unit1_bn2 False\n",
            "13 stage1_unit1_relu2 False\n",
            "14 zero_padding2d_3 False\n",
            "15 stage1_unit1_conv2 False\n",
            "16 stage1_unit1_sc False\n",
            "17 add False\n",
            "18 stage1_unit2_bn1 False\n",
            "19 stage1_unit2_relu1 False\n",
            "20 zero_padding2d_4 False\n",
            "21 stage1_unit2_conv1 False\n",
            "22 stage1_unit2_bn2 False\n",
            "23 stage1_unit2_relu2 False\n",
            "24 zero_padding2d_5 False\n",
            "25 stage1_unit2_conv2 False\n",
            "26 add_1 False\n",
            "27 stage2_unit1_bn1 False\n",
            "28 stage2_unit1_relu1 False\n",
            "29 zero_padding2d_6 False\n",
            "30 stage2_unit1_conv1 False\n",
            "31 stage2_unit1_bn2 False\n",
            "32 stage2_unit1_relu2 False\n",
            "33 zero_padding2d_7 False\n",
            "34 stage2_unit1_conv2 False\n",
            "35 stage2_unit1_sc True\n",
            "36 add_2 True\n",
            "37 stage2_unit2_bn1 True\n",
            "38 stage2_unit2_relu1 True\n",
            "39 zero_padding2d_8 True\n",
            "40 stage2_unit2_conv1 True\n",
            "41 stage2_unit2_bn2 True\n",
            "42 stage2_unit2_relu2 True\n",
            "43 zero_padding2d_9 True\n",
            "44 stage2_unit2_conv2 True\n",
            "45 add_3 True\n",
            "46 stage3_unit1_bn1 True\n",
            "47 stage3_unit1_relu1 True\n",
            "48 zero_padding2d_10 True\n",
            "49 stage3_unit1_conv1 True\n",
            "50 stage3_unit1_bn2 True\n",
            "51 stage3_unit1_relu2 True\n",
            "52 zero_padding2d_11 True\n",
            "53 stage3_unit1_conv2 True\n",
            "54 stage3_unit1_sc True\n",
            "55 add_4 True\n",
            "56 stage3_unit2_bn1 True\n",
            "57 stage3_unit2_relu1 True\n",
            "58 zero_padding2d_12 True\n",
            "59 stage3_unit2_conv1 True\n",
            "60 stage3_unit2_bn2 True\n",
            "61 stage3_unit2_relu2 True\n",
            "62 zero_padding2d_13 True\n",
            "63 stage3_unit2_conv2 True\n",
            "64 add_5 True\n",
            "65 stage4_unit1_bn1 True\n",
            "66 stage4_unit1_relu1 True\n",
            "67 zero_padding2d_14 True\n",
            "68 stage4_unit1_conv1 True\n",
            "69 stage4_unit1_bn2 True\n",
            "70 stage4_unit1_relu2 True\n",
            "71 zero_padding2d_15 True\n",
            "72 stage4_unit1_conv2 True\n",
            "73 stage4_unit1_sc True\n",
            "74 add_6 True\n",
            "75 stage4_unit2_bn1 True\n",
            "76 stage4_unit2_relu1 True\n",
            "77 zero_padding2d_16 True\n",
            "78 stage4_unit2_conv1 True\n",
            "79 stage4_unit2_bn2 True\n",
            "80 stage4_unit2_relu2 True\n",
            "81 zero_padding2d_17 True\n",
            "82 stage4_unit2_conv2 True\n",
            "83 add_7 True\n",
            "84 bn1 True\n",
            "85 relu1 True\n",
            "86 pool1 True\n",
            "87 fc1 True\n",
            "88 dense True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2eux2vSQ4d-"
      },
      "source": [
        "newInput = Input(batch_shape=(None, 32, 32, 3))\r\n",
        "resizedImg = Lambda(lambda image: ktf.image.resize(image, (224, 224)))(newInput)\r\n",
        "newOutputs = model(resizedImg)\r\n",
        "model = Model(newInput, newOutputs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhYMg5wDGLls"
      },
      "source": [
        "BATCH_SIZE =100\n",
        "STEPS_PER_EPOCH =len(X_train)//BATCH_SIZE \n",
        "\n",
        "step = tf.Variable(0, trainable=False)\n",
        "boundaries = [40*STEPS_PER_EPOCH,60*STEPS_PER_EPOCH,80*STEPS_PER_EPOCH]\n",
        "values = [ 0.1, 0.01,0.001,0.0001]\n",
        "learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries, values)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtTrzDGTZNDX"
      },
      "source": [
        "opt = SGD(learning_rate=learning_rate_fn)#,momentum=0.9,decay=0.01,nesterov=False\n",
        "#opt = Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.99,epsilon=0.1,amsgrad=False,name=\"Adam\",)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBYnLBGlFN2o"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foLD5c3UHD2X",
        "outputId": "de2f7fad-df1b-4797-8c73-fbcba4777eea"
      },
      "source": [
        "history =model.fit(X_train, y_train, batch_size=100,\n",
        "                   steps_per_epoch=len(X_train) // 100,epochs=100,\n",
        "                   validation_data=(x_test,y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 109s 217ms/step - loss: 3.0047 - accuracy: 0.2704 - val_loss: 5.8201 - val_accuracy: 0.1053\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 1.1181 - accuracy: 0.6204 - val_loss: 3.3272 - val_accuracy: 0.1687\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.7909 - accuracy: 0.7456 - val_loss: 2.8515 - val_accuracy: 0.2136\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.6210 - accuracy: 0.8066 - val_loss: 3.1717 - val_accuracy: 0.2761\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.4975 - accuracy: 0.8472 - val_loss: 1.6755 - val_accuracy: 0.4726\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.4029 - accuracy: 0.8805 - val_loss: 1.6751 - val_accuracy: 0.5675\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.3166 - accuracy: 0.9092 - val_loss: 1.1918 - val_accuracy: 0.6676\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.2519 - accuracy: 0.9297 - val_loss: 1.3908 - val_accuracy: 0.6258\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.1837 - accuracy: 0.9552 - val_loss: 1.4603 - val_accuracy: 0.6087\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.1386 - accuracy: 0.9687 - val_loss: 3.7793 - val_accuracy: 0.3543\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 0.0931 - accuracy: 0.9828 - val_loss: 3.3408 - val_accuracy: 0.4081\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0706 - accuracy: 0.9888 - val_loss: 2.9190 - val_accuracy: 0.4451\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0519 - accuracy: 0.9939 - val_loss: 0.7275 - val_accuracy: 0.8185\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0301 - accuracy: 0.9988 - val_loss: 0.7243 - val_accuracy: 0.8210\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0226 - accuracy: 0.9996 - val_loss: 0.5118 - val_accuracy: 0.8590\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0193 - accuracy: 0.9999 - val_loss: 0.4868 - val_accuracy: 0.8696\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0172 - accuracy: 0.9999 - val_loss: 0.4873 - val_accuracy: 0.8660\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0158 - accuracy: 0.9999 - val_loss: 0.4721 - val_accuracy: 0.8740\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.8706\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8679\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8734\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.8777\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8758\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8705\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8752\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 111s 221ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8739\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.8737\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.8752\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8739\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 111s 221ms/step - loss: 0.2991 - accuracy: 0.9285 - val_loss: 2.6760 - val_accuracy: 0.4868\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0563 - accuracy: 0.9921 - val_loss: 0.5321 - val_accuracy: 0.8639\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0312 - accuracy: 0.9981 - val_loss: 0.5174 - val_accuracy: 0.8670\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0254 - accuracy: 0.9994 - val_loss: 0.5061 - val_accuracy: 0.8708\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0227 - accuracy: 0.9997 - val_loss: 0.4998 - val_accuracy: 0.8716\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0212 - accuracy: 0.9999 - val_loss: 0.4973 - val_accuracy: 0.8713\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0201 - accuracy: 0.9998 - val_loss: 0.4959 - val_accuracy: 0.8706\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.8726\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0186 - accuracy: 0.9999 - val_loss: 0.4862 - val_accuracy: 0.8727\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8740\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 111s 221ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8726\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.8735\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.8732\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.8738\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.8734\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.8749\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8752\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8743\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8753\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.8748\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0145 - accuracy: 0.9999 - val_loss: 0.4697 - val_accuracy: 0.8754\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.8752\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.8753\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.8759\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.8756\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8752\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8752\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8758\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8756\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.8754\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8766\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.8766\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.8761\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8758\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8758\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.8770\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8766\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8763\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.8758\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 111s 221ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.8761\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8751\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.8760\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8764\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8759\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.8760\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 110s 221ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.8760\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8760\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8753\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8753\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.8758\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.8761\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8752\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8767\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.8753\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8752\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 109s 218ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8759\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8761\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8761\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8756\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.8764\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.8756\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 109s 219ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8763\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 109s 218ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8763\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.8759\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8766\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8751\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8768\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8764\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 110s 219ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8760\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8758\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 110s 220ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.8756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0FyvZOoHKQf"
      },
      "source": [
        "#model.save('cifar10.simplenet2.h5')\n",
        "                 \n",
        "#model=load_model('cifar10_01.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50eDgXQ7HQlZ",
        "outputId": "dc626a62-49d5-4112-da5b-ce0e24af9b59"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "labels1 = np.arange(num_classes)\n",
        "print('Auc = %f' %  (roc_auc_score(y_test,  y_pred.round(),average='macro',multi_class='ovo',labels=labels1)))\n",
        "print('f1_score = %f' % (f1_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('precision = %f' % (precision_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('recall  = %f' % (recall_score(y_test, y_pred.round(), average=\"macro\")))\n",
        "print('accuracy  = %f' % (accuracy_score(y_test, y_pred.round()))) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc = 0.926217\n",
            "f1_score = 0.878494\n",
            "precision = 0.894163\n",
            "recall  = 0.863700\n",
            "accuracy  = 0.863700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "T7uXlIIsHVwX",
        "outputId": "7aafb6ec-886e-4dfc-dc77-65d7684bd3c0"
      },
      "source": [
        "plothist(history)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}